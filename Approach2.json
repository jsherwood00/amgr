{
  "nodes": [
    {
      "id": "pinecone_0",
      "position": {
        "x": 1723.914838436207,
        "y": 783.3651845618841
      },
      "type": "customNode",
      "data": {
        "id": "pinecone_0",
        "label": "Pinecone",
        "version": 5,
        "name": "pinecone",
        "type": "Pinecone",
        "baseClasses": [
          "Pinecone",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "Upsert embedded data and perform similarity or mmr search using Pinecone, a leading fully managed hosted vector database",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "pineconeApi"
            ],
            "id": "pinecone_0-input-credential-credential"
          },
          {
            "label": "Pinecone Index",
            "name": "pineconeIndex",
            "type": "string",
            "id": "pinecone_0-input-pineconeIndex-string"
          },
          {
            "label": "Pinecone Namespace",
            "name": "pineconeNamespace",
            "type": "string",
            "placeholder": "my-first-namespace",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-pineconeNamespace-string"
          },
          {
            "label": "File Upload",
            "name": "fileUpload",
            "description": "Allow file upload on the chat",
            "hint": {
              "label": "How to use",
              "value": "\n**File Upload**\n\nThis allows file upload on the chat. Uploaded files will be upserted on the fly to the vector store.\n\n**Note:**\n- You can only turn on file upload for one vector store at a time.\n- At least one Document Loader node should be connected to the document input.\n- Document Loader should be file types like PDF, DOCX, TXT, etc.\n\n**How it works**\n- Uploaded files will have the metadata updated with the chatId.\n- This will allow the file to be associated with the chatId.\n- When querying, metadata will be filtered by chatId to retrieve files associated with the chatId.\n"
            },
            "type": "boolean",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-fileUpload-boolean"
          },
          {
            "label": "Pinecone Text Key",
            "name": "pineconeTextKey",
            "description": "The key in the metadata for storing text. Default to `text`",
            "type": "string",
            "placeholder": "text",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-pineconeTextKey-string"
          },
          {
            "label": "Pinecone Metadata Filter",
            "name": "pineconeMetadataFilter",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "pinecone_0-input-pineconeMetadataFilter-json"
          },
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-topK-number"
          },
          {
            "label": "Search Type",
            "name": "searchType",
            "type": "options",
            "default": "similarity",
            "options": [
              {
                "label": "Similarity",
                "name": "similarity"
              },
              {
                "label": "Max Marginal Relevance",
                "name": "mmr"
              }
            ],
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-searchType-options"
          },
          {
            "label": "Fetch K (for MMR Search)",
            "name": "fetchK",
            "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search type is MMR",
            "placeholder": "20",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-fetchK-number"
          },
          {
            "label": "Lambda (for MMR Search)",
            "name": "lambda",
            "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 corresponds to maximum diversity and 1 to minimum diversity. Used only when the search type is MMR",
            "placeholder": "0.5",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-lambda-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "pinecone_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "pinecone_0-input-embeddings-Embeddings"
          },
          {
            "label": "Record Manager",
            "name": "recordManager",
            "type": "RecordManager",
            "description": "Keep track of the record to prevent duplication",
            "optional": true,
            "id": "pinecone_0-input-recordManager-RecordManager"
          }
        ],
        "inputs": {
          "document": "",
          "embeddings": "{{openAIEmbeddings_0.data.instance}}",
          "recordManager": "",
          "pineconeIndex": "amgr-chunked",
          "pineconeNamespace": "",
          "fileUpload": "",
          "pineconeTextKey": "parent_asin",
          "pineconeMetadataFilter": "",
          "topK": "5",
          "searchType": "similarity",
          "fetchK": "",
          "lambda": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Pinecone Retriever",
                "description": "",
                "type": "Pinecone | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "pinecone_0-output-vectorStore-Pinecone|VectorStore",
                "name": "vectorStore",
                "label": "Pinecone Vector Store",
                "description": "",
                "type": "Pinecone | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 605,
      "selected": false,
      "positionAbsolute": {
        "x": 1723.914838436207,
        "y": 783.3651845618841
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": 1058.0176473094748,
        "y": 773.0687495902105
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 7,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-3.5-turbo",
            "id": "chatOpenAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string"
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-proxyUrl-string"
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_0-input-stopSequence-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, Conversational Agent, Tool Agent",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-imageResolution-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-3.5-turbo",
          "temperature": 0.9,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "basepath": "",
          "proxyUrl": "",
          "stopSequence": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 669,
      "selected": false,
      "positionAbsolute": {
        "x": 1058.0176473094748,
        "y": 773.0687495902105
      },
      "dragging": false
    },
    {
      "id": "seqStart_0",
      "position": {
        "x": 1198.9964338613447,
        "y": 88.10667456912557
      },
      "type": "customNode",
      "data": {
        "id": "seqStart_0",
        "label": "Start",
        "version": 2,
        "name": "seqStart",
        "type": "Start",
        "baseClasses": [
          "Start"
        ],
        "category": "Sequential Agents",
        "description": "Starting point of the conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
            "id": "seqStart_0-input-model-BaseChatModel"
          },
          {
            "label": "Agent Memory",
            "name": "agentMemory",
            "type": "BaseCheckpointSaver",
            "description": "Save the state of the agent",
            "optional": true,
            "id": "seqStart_0-input-agentMemory-BaseCheckpointSaver"
          },
          {
            "label": "State",
            "name": "state",
            "type": "State",
            "description": "State is an object that is updated by nodes in the graph, passing from one node to another. By default, state contains \"messages\" that got updated with each message sent and received.",
            "optional": true,
            "id": "seqStart_0-input-state-State"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "seqStart_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{chatOpenAI_0.data.instance}}",
          "agentMemory": "",
          "state": "",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "seqStart_0-output-seqStart-Start",
            "name": "seqStart",
            "label": "Start",
            "description": "Starting point of the conversation",
            "type": "Start"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 382,
      "positionAbsolute": {
        "x": 1198.9964338613447,
        "y": 88.10667456912557
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "seqEnd_0",
      "position": {
        "x": 2759.180963626365,
        "y": 271.65252812228033
      },
      "type": "customNode",
      "data": {
        "id": "seqEnd_0",
        "label": "End",
        "version": 2,
        "name": "seqEnd",
        "type": "End",
        "baseClasses": [
          "End"
        ],
        "category": "Sequential Agents",
        "description": "End conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Agent | Condition | LLM | Tool Node",
            "name": "sequentialNode",
            "type": "Agent | Condition | LLMNode | ToolNode",
            "id": "seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
          }
        ],
        "inputs": {
          "sequentialNode": "{{seqAgent_2.data.instance}}"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 143,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 2759.180963626365,
        "y": 271.65252812228033
      }
    },
    {
      "id": "seqAgent_3",
      "position": {
        "x": 1505.9314623571968,
        "y": -145.7865003383584
      },
      "type": "customNode",
      "data": {
        "id": "seqAgent_3",
        "label": "Agent",
        "version": 3.1,
        "name": "seqAgent",
        "type": "Agent",
        "baseClasses": [
          "Agent"
        ],
        "category": "Sequential Agents",
        "description": "Agent that can execute tools",
        "inputParams": [
          {
            "label": "Agent Name",
            "name": "agentName",
            "type": "string",
            "placeholder": "Agent",
            "id": "seqAgent_3-input-agentName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "seqAgent_3-input-systemMessagePrompt-string"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_3-input-humanMessagePrompt-string"
          },
          {
            "label": "Messages History",
            "name": "messageHistory",
            "description": "Return a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples",
            "type": "code",
            "hideCodeExecute": true,
            "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ðŸ¦œ 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_3-input-messageHistory-code"
          },
          {
            "label": "Require Approval",
            "name": "interrupt",
            "description": "Require approval before executing tools. Will proceed when tools are not called",
            "type": "boolean",
            "optional": true,
            "id": "seqAgent_3-input-interrupt-boolean"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "seqAgent_3-input-promptValues-json"
          },
          {
            "label": "Approval Prompt",
            "name": "approvalPrompt",
            "description": "Prompt for approval. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "You are about to execute tool: {tools}. Ask if user want to proceed",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_3-input-approvalPrompt-string"
          },
          {
            "label": "Approve Button Text",
            "name": "approveButtonText",
            "description": "Text for approve button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "Yes",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_3-input-approveButtonText-string"
          },
          {
            "label": "Reject Button Text",
            "name": "rejectButtonText",
            "description": "Text for reject button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "No",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_3-input-rejectButtonText-string"
          },
          {
            "label": "Update State",
            "name": "updateStateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedUpdateStateMemoryTab",
            "additionalParams": true,
            "default": "updateStateMemoryUI",
            "tabs": [
              {
                "label": "Update State (Table)",
                "name": "updateStateMemoryUI",
                "type": "datagrid",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "type": "asyncSingleSelect",
                    "loadMethod": "loadStateKeys",
                    "flex": 0.5,
                    "editable": true
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "type": "freeSolo",
                    "valueOptions": [
                      {
                        "label": "Agent Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "Used Tools (array)",
                        "value": "$flow.output.usedTools"
                      },
                      {
                        "label": "First Tool Output (string)",
                        "value": "$flow.output.usedTools[0].toolOutput"
                      },
                      {
                        "label": "Source Documents (array)",
                        "value": "$flow.output.sourceDocuments"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      },
                      {
                        "label": "Input Question (string)",
                        "value": "$flow.input"
                      },
                      {
                        "label": "Session Id (string)",
                        "value": "$flow.sessionId"
                      },
                      {
                        "label": "Chat Id (string)",
                        "value": "$flow.chatId"
                      },
                      {
                        "label": "Chatflow Id (string)",
                        "value": "$flow.chatflowId"
                      }
                    ],
                    "editable": true,
                    "flex": 1
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Update State (Code)",
                "name": "updateStateMemoryCode",
                "type": "code",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqAgent_3-input-updateStateMemory-tabs"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_3-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "seqAgent_3-input-tools-Tool"
          },
          {
            "label": "Start | Agent | Condition | LLM | Tool Node",
            "name": "sequentialNode",
            "type": "Start | Agent | Condition | LLMNode | ToolNode",
            "list": true,
            "id": "seqAgent_3-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this agent",
            "id": "seqAgent_3-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "agentName": "Agent1",
          "systemMessagePrompt": "The user provides you with the product they are looking for. If not, or if their input does not make sense for describing a product at all, such as being a verb, or is best described as gibberish, respond with \"%%ss\". Otherwise, formulate an ideal product title that would match this query, along with a matching product category.  Then, return to the user in a numbered list: 1) their original query, 2) the title you have developed, 3) the chosen category. The possible categories are the following:\n\n('All Beauty',)\n('All Electronics',)\n('Amazon Devices',)\n('Amazon Elements',)\n('AMAZON FASHION',)\n('Amazon Fire TV',)\n('Amazon Home',)\n('Apple Products',)\n('Appliances',)\n('Appstore for Android',)\n('Arts, Crafts & Sewing',)\n('Audible Audiobooks',)\n('Automotive',)\n('Baby',)\n('Books',)\n('Buy a Kindle',)\n('Camera & Photo',)\n('Car Electronics',)\n('Cell Phones & Accessories',)\n('Collectible Coins',)\n('Collectibles & Fine Art',)\n('Computers',)\n('Digital Music',)\n('Entertainment',)\n('Fine Art',)\n('Fire Phone',)\n('Gift Cards',)\n('Gifts',)\n('GPS & Navigation',)\n('Grocery',)\n('Handmade',)\n('Health & Personal Care',)\n('Home Audio & Theater',)\n('Industrial & Scientific',)\n('Magazine Subscriptions',)\n('Movies & TV',)\n('Musical Instruments',)\n('Office Products',)\n('Pet Supplies',)\n('Portable Audio & Accessories',)\n('Premium Beauty',)\n('Software',)\n('Sports Collectibles',)\n('Sports & Outdoors',)\n('SUBSCRIPTION BOXES',)\n('Tools & Home Improvement',)\n('Toys & Games',)\n('Unique Finds',)\n('Video Games',)",
          "humanMessagePrompt": "",
          "messageHistory": "",
          "tools": [],
          "sequentialNode": [
            "{{seqStart_0.data.instance}}"
          ],
          "model": "",
          "interrupt": "",
          "promptValues": "",
          "approvalPrompt": "You are about to execute tool: {tools}. Ask if user want to proceed",
          "approveButtonText": "Yes",
          "rejectButtonText": "No",
          "updateStateMemory": "updateStateMemoryUI",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "seqAgent_3-output-seqAgent-Agent",
            "name": "seqAgent",
            "label": "Agent",
            "description": "Agent that can execute tools",
            "type": "Agent"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 878,
      "selected": false,
      "positionAbsolute": {
        "x": 1505.9314623571968,
        "y": -145.7865003383584
      },
      "dragging": false
    },
    {
      "id": "retrieverTool_0",
      "position": {
        "x": 2023.5957779721816,
        "y": 775.455938563363
      },
      "type": "customNode",
      "data": {
        "id": "retrieverTool_0",
        "label": "Retriever Tool",
        "version": 3,
        "name": "retrieverTool",
        "type": "RetrieverTool",
        "baseClasses": [
          "RetrieverTool",
          "DynamicTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use a retriever as allowed tool for agent",
        "inputParams": [
          {
            "label": "Retriever Name",
            "name": "name",
            "type": "string",
            "placeholder": "search_state_of_union",
            "id": "retrieverTool_0-input-name-string"
          },
          {
            "label": "Retriever Description",
            "name": "description",
            "type": "string",
            "description": "When should agent uses to retrieve documents",
            "rows": 3,
            "placeholder": "Searches and returns documents regarding the state-of-the-union.",
            "id": "retrieverTool_0-input-description-string"
          },
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "retrieverTool_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Additional Metadata Filter",
            "name": "retrieverToolMetadataFilter",
            "type": "json",
            "description": "Add additional metadata filter on top of the existing filter from vector store",
            "optional": true,
            "additionalParams": true,
            "hint": {
              "label": "What can you filter?",
              "value": "Add additional filters to vector store. You can also filter with flow config, including the current \"state\":\n- `$flow.sessionId`\n- `$flow.chatId`\n- `$flow.chatflowId`\n- `$flow.input`\n- `$flow.state`\n"
            },
            "id": "retrieverTool_0-input-retrieverToolMetadataFilter-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Retriever",
            "name": "retriever",
            "type": "BaseRetriever",
            "id": "retrieverTool_0-input-retriever-BaseRetriever"
          }
        ],
        "inputs": {
          "name": "pinecone",
          "description": "ONLY IF THE QUERY DOES NOT CONTAIN \"%%SS\" and the user query does not contain garbage / nosensical text, query the database for the term provided by the user, and return the best matching top 5  result IDs .",
          "retriever": "{{pinecone_0.data.instance}}",
          "returnSourceDocuments": true,
          "retrieverToolMetadataFilter": ""
        },
        "outputAnchors": [
          {
            "id": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
            "name": "retrieverTool",
            "label": "RetrieverTool",
            "description": "Use a retriever as allowed tool for agent",
            "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 655,
      "selected": false,
      "positionAbsolute": {
        "x": 2023.5957779721816,
        "y": 775.455938563363
      },
      "dragging": false
    },
    {
      "id": "openAIEmbeddings_0",
      "position": {
        "x": 1419.931764312116,
        "y": 775.3949550190126
      },
      "type": "customNode",
      "data": {
        "id": "openAIEmbeddings_0",
        "label": "OpenAI Embeddings",
        "version": 4,
        "name": "openAIEmbeddings",
        "type": "OpenAIEmbeddings",
        "baseClasses": [
          "OpenAIEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "OpenAI API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "openAIEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "text-embedding-ada-002",
            "id": "openAIEmbeddings_0-input-modelName-asyncOptions"
          },
          {
            "label": "Strip New Lines",
            "name": "stripNewLines",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-stripNewLines-boolean"
          },
          {
            "label": "Batch Size",
            "name": "batchSize",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-batchSize-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-basepath-string"
          },
          {
            "label": "Dimensions",
            "name": "dimensions",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-dimensions-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "text-embedding-ada-002",
          "stripNewLines": "",
          "batchSize": "",
          "timeout": "",
          "basepath": "",
          "dimensions": ""
        },
        "outputAnchors": [
          {
            "id": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "name": "openAIEmbeddings",
            "label": "OpenAIEmbeddings",
            "description": "OpenAI API to generate embeddings for a given text",
            "type": "OpenAIEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 423,
      "selected": false,
      "positionAbsolute": {
        "x": 1419.931764312116,
        "y": 775.3949550190126
      },
      "dragging": false
    },
    {
      "id": "customTool_0",
      "position": {
        "x": 2377.4085636906048,
        "y": 774.2383517532642
      },
      "type": "customNode",
      "data": {
        "id": "customTool_0",
        "label": "Custom Tool",
        "version": 2,
        "name": "customTool",
        "type": "CustomTool",
        "baseClasses": [
          "CustomTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use custom tool you've created in Flowise within chatflow",
        "inputParams": [
          {
            "label": "Select Tool",
            "name": "selectedTool",
            "type": "asyncOptions",
            "loadMethod": "listTools",
            "id": "customTool_0-input-selectedTool-asyncOptions"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "description": "Return the output of the tool directly to the user",
            "type": "boolean",
            "optional": true,
            "id": "customTool_0-input-returnDirect-boolean"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedTool": "5c1eb244-0950-4a76-bf9c-544721f9987c",
          "returnDirect": false
        },
        "outputAnchors": [
          {
            "id": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
            "name": "customTool",
            "label": "CustomTool",
            "description": "Use custom tool you've created in Flowise within chatflow",
            "type": "CustomTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 372,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 2377.4085636906048,
        "y": 774.2383517532642
      }
    },
    {
      "id": "seqAgent_2",
      "position": {
        "x": 2365.2712913581477,
        "y": -146.26440500145327
      },
      "type": "customNode",
      "data": {
        "id": "seqAgent_2",
        "label": "Agent",
        "version": 3.1,
        "name": "seqAgent",
        "type": "Agent",
        "baseClasses": [
          "Agent"
        ],
        "category": "Sequential Agents",
        "description": "Agent that can execute tools",
        "inputParams": [
          {
            "label": "Agent Name",
            "name": "agentName",
            "type": "string",
            "placeholder": "Agent",
            "id": "seqAgent_2-input-agentName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "seqAgent_2-input-systemMessagePrompt-string"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-humanMessagePrompt-string"
          },
          {
            "label": "Messages History",
            "name": "messageHistory",
            "description": "Return a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples",
            "type": "code",
            "hideCodeExecute": true,
            "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ðŸ¦œ 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-messageHistory-code"
          },
          {
            "label": "Require Approval",
            "name": "interrupt",
            "description": "Require approval before executing tools. Will proceed when tools are not called",
            "type": "boolean",
            "optional": true,
            "id": "seqAgent_2-input-interrupt-boolean"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "seqAgent_2-input-promptValues-json"
          },
          {
            "label": "Approval Prompt",
            "name": "approvalPrompt",
            "description": "Prompt for approval. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "You are about to execute tool: {tools}. Ask if user want to proceed",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-approvalPrompt-string"
          },
          {
            "label": "Approve Button Text",
            "name": "approveButtonText",
            "description": "Text for approve button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "Yes",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-approveButtonText-string"
          },
          {
            "label": "Reject Button Text",
            "name": "rejectButtonText",
            "description": "Text for reject button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "No",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-rejectButtonText-string"
          },
          {
            "label": "Update State",
            "name": "updateStateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedUpdateStateMemoryTab",
            "additionalParams": true,
            "default": "updateStateMemoryUI",
            "tabs": [
              {
                "label": "Update State (Table)",
                "name": "updateStateMemoryUI",
                "type": "datagrid",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "type": "asyncSingleSelect",
                    "loadMethod": "loadStateKeys",
                    "flex": 0.5,
                    "editable": true
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "type": "freeSolo",
                    "valueOptions": [
                      {
                        "label": "Agent Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "Used Tools (array)",
                        "value": "$flow.output.usedTools"
                      },
                      {
                        "label": "First Tool Output (string)",
                        "value": "$flow.output.usedTools[0].toolOutput"
                      },
                      {
                        "label": "Source Documents (array)",
                        "value": "$flow.output.sourceDocuments"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      },
                      {
                        "label": "Input Question (string)",
                        "value": "$flow.input"
                      },
                      {
                        "label": "Session Id (string)",
                        "value": "$flow.sessionId"
                      },
                      {
                        "label": "Chat Id (string)",
                        "value": "$flow.chatId"
                      },
                      {
                        "label": "Chatflow Id (string)",
                        "value": "$flow.chatflowId"
                      }
                    ],
                    "editable": true,
                    "flex": 1
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Update State (Code)",
                "name": "updateStateMemoryCode",
                "type": "code",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqAgent_2-input-updateStateMemory-tabs"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "seqAgent_2-input-tools-Tool"
          },
          {
            "label": "Start | Agent | Condition | LLM | Tool Node",
            "name": "sequentialNode",
            "type": "Start | Agent | Condition | LLMNode | ToolNode",
            "list": true,
            "id": "seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this agent",
            "id": "seqAgent_2-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "agentName": "Agent3",
          "systemMessagePrompt": "If and only if you have received the input as \"%%ss\", respond with \"Hello, I am your virtual assistant here to help you find your ideal product\". Otherwise, and in all other cases, the user has provided a query along with a list of 100 product IDs. Use your RDS tool to retrieve the title, description, and feature columns for each product, and compare the combination of these with the user's query. Return to the user the top 5 products. For each product returned to the user, the title and description should be provided. Fill in the detail's about the product using RDS, as necessary.",
          "humanMessagePrompt": "",
          "messageHistory": "",
          "tools": [
            "{{customTool_0.data.instance}}"
          ],
          "sequentialNode": [
            "{{seqAgent_4.data.instance}}"
          ],
          "model": "",
          "interrupt": "",
          "promptValues": "",
          "approvalPrompt": "You are about to execute tool: {tools}. Ask if user want to proceed",
          "approveButtonText": "Yes",
          "rejectButtonText": "No",
          "updateStateMemory": "updateStateMemoryUI",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "seqAgent_2-output-seqAgent-Agent",
            "name": "seqAgent",
            "label": "Agent",
            "description": "Agent that can execute tools",
            "type": "Agent"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 878,
      "selected": false,
      "positionAbsolute": {
        "x": 2365.2712913581477,
        "y": -146.26440500145327
      },
      "dragging": false
    },
    {
      "id": "seqAgent_4",
      "position": {
        "x": 1954.6777379928772,
        "y": -140.92780293022682
      },
      "type": "customNode",
      "data": {
        "id": "seqAgent_4",
        "label": "Agent",
        "version": 3.1,
        "name": "seqAgent",
        "type": "Agent",
        "baseClasses": [
          "Agent"
        ],
        "category": "Sequential Agents",
        "description": "Agent that can execute tools",
        "inputParams": [
          {
            "label": "Agent Name",
            "name": "agentName",
            "type": "string",
            "placeholder": "Agent",
            "id": "seqAgent_4-input-agentName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "seqAgent_4-input-systemMessagePrompt-string"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_4-input-humanMessagePrompt-string"
          },
          {
            "label": "Messages History",
            "name": "messageHistory",
            "description": "Return a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples",
            "type": "code",
            "hideCodeExecute": true,
            "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ðŸ¦œ 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_4-input-messageHistory-code"
          },
          {
            "label": "Require Approval",
            "name": "interrupt",
            "description": "Require approval before executing tools. Will proceed when tools are not called",
            "type": "boolean",
            "optional": true,
            "id": "seqAgent_4-input-interrupt-boolean"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "seqAgent_4-input-promptValues-json"
          },
          {
            "label": "Approval Prompt",
            "name": "approvalPrompt",
            "description": "Prompt for approval. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "You are about to execute tool: {tools}. Ask if user want to proceed",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_4-input-approvalPrompt-string"
          },
          {
            "label": "Approve Button Text",
            "name": "approveButtonText",
            "description": "Text for approve button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "Yes",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_4-input-approveButtonText-string"
          },
          {
            "label": "Reject Button Text",
            "name": "rejectButtonText",
            "description": "Text for reject button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "No",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_4-input-rejectButtonText-string"
          },
          {
            "label": "Update State",
            "name": "updateStateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedUpdateStateMemoryTab",
            "additionalParams": true,
            "default": "updateStateMemoryUI",
            "tabs": [
              {
                "label": "Update State (Table)",
                "name": "updateStateMemoryUI",
                "type": "datagrid",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "type": "asyncSingleSelect",
                    "loadMethod": "loadStateKeys",
                    "flex": 0.5,
                    "editable": true
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "type": "freeSolo",
                    "valueOptions": [
                      {
                        "label": "Agent Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "Used Tools (array)",
                        "value": "$flow.output.usedTools"
                      },
                      {
                        "label": "First Tool Output (string)",
                        "value": "$flow.output.usedTools[0].toolOutput"
                      },
                      {
                        "label": "Source Documents (array)",
                        "value": "$flow.output.sourceDocuments"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      },
                      {
                        "label": "Input Question (string)",
                        "value": "$flow.input"
                      },
                      {
                        "label": "Session Id (string)",
                        "value": "$flow.sessionId"
                      },
                      {
                        "label": "Chat Id (string)",
                        "value": "$flow.chatId"
                      },
                      {
                        "label": "Chatflow Id (string)",
                        "value": "$flow.chatflowId"
                      }
                    ],
                    "editable": true,
                    "flex": 1
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Update State (Code)",
                "name": "updateStateMemoryCode",
                "type": "code",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqAgent_4-input-updateStateMemory-tabs"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_4-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "seqAgent_4-input-tools-Tool"
          },
          {
            "label": "Start | Agent | Condition | LLM | Tool Node",
            "name": "sequentialNode",
            "type": "Start | Agent | Condition | LLMNode | ToolNode",
            "list": true,
            "id": "seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this agent",
            "id": "seqAgent_4-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "agentName": "Agent2",
          "systemMessagePrompt": "If you have received nonsensical text or \"%%ss\", respond with \"%%ss\". Otherwise, the user has provided you with a title of the product they are searching for, and its associated category. Use this to obtain the top 5 vectors with the highest similarity score to the title + description. Then, list out the top IDs. Note that each vector returns 20 product IDS, so you should output all 20 from each vector, returning a list of 100 . The output of your work should be the original user query, labeled as such, and a list of 100 product IDs, labeled with number points.",
          "humanMessagePrompt": "",
          "messageHistory": "",
          "tools": [
            "{{retrieverTool_0.data.instance}}"
          ],
          "sequentialNode": [
            "{{seqAgent_3.data.instance}}"
          ],
          "model": "",
          "interrupt": "",
          "promptValues": "",
          "approvalPrompt": "You are about to execute tool: {tools}. Ask if user want to proceed",
          "approveButtonText": "Yes",
          "rejectButtonText": "No",
          "updateStateMemory": "updateStateMemoryUI",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "seqAgent_4-output-seqAgent-Agent",
            "name": "seqAgent",
            "label": "Agent",
            "description": "Agent that can execute tools",
            "type": "Agent"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 878,
      "selected": false,
      "positionAbsolute": {
        "x": 1954.6777379928772,
        "y": -140.92780293022682
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "seqStart_0",
      "targetHandle": "seqStart_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-seqStart_0-seqStart_0-input-model-BaseChatModel"
    },
    {
      "source": "seqStart_0",
      "sourceHandle": "seqStart_0-output-seqStart-Start",
      "target": "seqAgent_3",
      "targetHandle": "seqAgent_3-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode",
      "type": "buttonedge",
      "id": "seqStart_0-seqStart_0-output-seqStart-Start-seqAgent_3-seqAgent_3-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
    },
    {
      "source": "openAIEmbeddings_0",
      "sourceHandle": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
      "target": "pinecone_0",
      "targetHandle": "pinecone_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "openAIEmbeddings_0-openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-pinecone_0-pinecone_0-input-embeddings-Embeddings"
    },
    {
      "source": "pinecone_0",
      "sourceHandle": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
      "target": "retrieverTool_0",
      "targetHandle": "retrieverTool_0-input-retriever-BaseRetriever",
      "type": "buttonedge",
      "id": "pinecone_0-pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever-retrieverTool_0-retrieverTool_0-input-retriever-BaseRetriever"
    },
    {
      "source": "seqAgent_2",
      "sourceHandle": "seqAgent_2-output-seqAgent-Agent",
      "target": "seqEnd_0",
      "targetHandle": "seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode",
      "type": "buttonedge",
      "id": "seqAgent_2-seqAgent_2-output-seqAgent-Agent-seqEnd_0-seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
    },
    {
      "source": "seqAgent_3",
      "sourceHandle": "seqAgent_3-output-seqAgent-Agent",
      "target": "seqAgent_4",
      "targetHandle": "seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode",
      "type": "buttonedge",
      "id": "seqAgent_3-seqAgent_3-output-seqAgent-Agent-seqAgent_4-seqAgent_4-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
    },
    {
      "source": "seqAgent_4",
      "sourceHandle": "seqAgent_4-output-seqAgent-Agent",
      "target": "seqAgent_2",
      "targetHandle": "seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode",
      "type": "buttonedge",
      "id": "seqAgent_4-seqAgent_4-output-seqAgent-Agent-seqAgent_2-seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
    },
    {
      "source": "customTool_0",
      "sourceHandle": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
      "target": "seqAgent_2",
      "targetHandle": "seqAgent_2-input-tools-Tool",
      "type": "buttonedge",
      "id": "customTool_0-customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable-seqAgent_2-seqAgent_2-input-tools-Tool"
    },
    {
      "source": "retrieverTool_0",
      "sourceHandle": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
      "target": "seqAgent_4",
      "targetHandle": "seqAgent_4-input-tools-Tool",
      "type": "buttonedge",
      "id": "retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqAgent_4-seqAgent_4-input-tools-Tool"
    }
  ]
}